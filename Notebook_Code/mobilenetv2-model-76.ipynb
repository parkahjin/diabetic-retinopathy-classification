{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":418031,"sourceType":"datasetVersion","datasetId":131128},{"sourceId":13676802,"sourceType":"datasetVersion","datasetId":8696869},{"sourceId":13687858,"sourceType":"datasetVersion","datasetId":8705445}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ===================================================================\n# Cell 1: ë°ì´í„° ë¡œë“œ + GPU ì„¤ì •\n# ===================================================================\nimport numpy as np\nimport gc\nimport tensorflow as tf\nimport psutil\n\nprint(\"GPU ë©”ëª¨ë¦¬ ë™ì  í• ë‹¹ ì„¤ì • ì¤‘...\\n\")\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(\"[ì™„ë£Œ] GPU ë©”ëª¨ë¦¬ ë™ì  í• ë‹¹ ì„¤ì • ì™„ë£Œ!\\n\")\n    except RuntimeError as e:\n        print(f\"[ê²½ê³ ] GPU ì„¤ì • ê²½ê³ : {e}\\n\")\n\nprint(\"ë°ì´í„° ë¡œë“œ ì¤‘...\\n\")\nDATA_PATH = '/kaggle/input/xy-data'\nX_train = np.load(f'{DATA_PATH}/X_train.npy')\ny_train = np.load(f'{DATA_PATH}/y_train.npy')\nX_val = np.load(f'{DATA_PATH}/X_val.npy')\ny_val = np.load(f'{DATA_PATH}/y_val.npy')\n\nprint(\"[ì™„ë£Œ] ë¡œë“œ ì™„ë£Œ!\")\nprint(f\"   X_train: {X_train.shape}\")\nprint(f\"   y_train: {y_train.shape}\")\nprint(f\"   X_val: {X_val.shape}\")\nprint(f\"   y_val: {y_val.shape}\")\n\nIMG_SIZE = X_train.shape[1]\nprint(f\"\\n[í™•ì¸] IMG_SIZE: {IMG_SIZE}\")\nprint(f\"   ë°ì´í„° ë©”ëª¨ë¦¬: {(X_train.nbytes + X_val.nbytes) / (1024**3):.2f} GB\")\n\nram = psutil.virtual_memory()\nprint(f\"\\n[ë©”ëª¨ë¦¬] RAM: {ram.used/1024**3:.1f}GB / {ram.total/1024**3:.1f}GB ({ram.percent:.1f}%)\")\n\nprint(\"\\n[ëª©í‘œ] MobileNetV2 ê·¹í•œ ê°œì„ ìœ¼ë¡œ 77.5-78% ë‹¬ì„±!\")\nprint(\"=\"*60)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================================================================\n# Cell 2: ëª¨ë¸ ì •ì˜ (ê²€ì¦ëœ ì„¤ì • + ì•½ê°„ ê°œì„ )\n# ===================================================================\nprint(\"ğŸ”¥ ê²€ì¦ëœ ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ êµ¬ì¶•...\\n\")\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, callbacks\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.optimizers import Adam\n\ngc.collect()\n\n# ===================================================================\n# 1. Focal Loss (ì›ë˜ ì„±ê³µí–ˆë˜ ì„¤ì •!)\n# ===================================================================\ndef focal_loss(gamma=1.5, alpha=0.5):  # ì›ë˜ëŒ€ë¡œ!\n    def focal_loss_fixed(y_true, y_pred):\n        epsilon = tf.keras.backend.epsilon()\n        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n        \n        y_true = tf.cast(y_true, tf.float32)\n        p_t = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n        alpha_t = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n        focal_weight = tf.pow(1.0 - p_t, gamma)\n        focal_loss = -alpha_t * focal_weight * tf.math.log(p_t)\n        \n        return tf.reduce_mean(focal_loss)\n    \n    return focal_loss_fixed\n\nprint(\"[ì„¤ì •] Focal Loss: gamma=1.5 (ê²€ì¦ë¨), alpha=0.5\\n\")\n\n# ===================================================================\n# 2. ë°ì´í„° ì¦ê°• (ì›ë˜ ì„¤ì • + ì•½ê°„ë§Œ ì¶”ê°€)\n# ===================================================================\ndata_augmentation = keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.1),    # ì›ë˜ëŒ€ë¡œ\n    layers.RandomZoom(0.1),        # ì›ë˜ëŒ€ë¡œ\n    layers.RandomContrast(0.1),    # ì´ê²ƒë§Œ ì¶”ê°€\n], name='data_augmentation')\n\nprint(\"[ì„¤ì •] ë°ì´í„° ì¦ê°• (ê²€ì¦ëœ ì„¤ì •):\")\nprint(\"      - RandomFlip\")\nprint(\"      - RandomRotation: 0.1\")\nprint(\"      - RandomZoom: 0.1\")\nprint(\"      - RandomContrast: 0.1 (ì¶”ê°€)\\n\")\n\n# ===================================================================\n# 3. MobileNetV2\n# ===================================================================\nprint(\"MobileNetV2 ë¡œë”©...\\n\")\n\nbase_model = MobileNetV2(\n    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n    include_top=False,\n    weights='imagenet'\n)\n\nprint(f\"[ì™„ë£Œ] MobileNetV2 ë¡œë“œ!\")\nprint(f\"      ì „ì²´ layers: {len(base_model.layers)}\\n\")\n\n# ===================================================================\n# 4. Fine-tuning (ì›ë˜ ì„¤ì • + ì•½ê°„ë§Œ ì¦ê°€)\n# ===================================================================\nFINE_TUNE_LAYERS = 50  # ì›ë˜ëŠ” 40, 50ìœ¼ë¡œ ì•½ê°„ë§Œ ì¦ê°€\n\nprint(f\"[ì„¤ì •] Fine-tuning:\")\nprint(f\"      - Freeze: ì²˜ìŒ {len(base_model.layers) - FINE_TUNE_LAYERS} layers\")\nprint(f\"      - Fine-tune: ë§ˆì§€ë§‰ {FINE_TUNE_LAYERS} layers\\n\")\n\nfor layer in base_model.layers[:-FINE_TUNE_LAYERS]:\n    layer.trainable = False\n    \nfor layer in base_model.layers[-FINE_TUNE_LAYERS:]:\n    layer.trainable = True\n\n# ===================================================================\n# 5. ëª¨ë¸ êµ¬ì¶• (ì›ë˜ ì„¤ì • ê·¸ëŒ€ë¡œ)\n# ===================================================================\nmodel = models.Sequential([\n    layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(256, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(1, activation='sigmoid', dtype='float32')\n])\n\nprint(\"[ì™„ë£Œ] ëª¨ë¸ êµ¬ì¶• (ê²€ì¦ëœ êµ¬ì¡°)\\n\")\n\n# ===================================================================\n# 6. ì»´íŒŒì¼ (ì›ë˜ ì„¤ì • ê·¸ëŒ€ë¡œ)\n# ===================================================================\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0005),  # ì›ë˜ëŒ€ë¡œ\n    loss=focal_loss(gamma=1.5, alpha=0.5),\n    metrics=['accuracy', \n             tf.keras.metrics.AUC(name='auc'),\n             tf.keras.metrics.Precision(name='precision'),\n             tf.keras.metrics.Recall(name='recall')]\n)\n\nprint(\"=\"*60)\nprint(\"ğŸ“Š ëª¨ë¸ ìš”ì•½\")\nprint(\"=\"*60)\nmodel.summary()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… ê²€ì¦ëœ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\")\nprint(\"=\"*60)\nprint(f\"ëª¨ë¸: MobileNetV2\")\nprint(f\"ì†ì‹¤: Focal Loss (gamma=1.5)\")\nprint(f\"LR: 0.0005\")\nprint(f\"Fine-tuning: {FINE_TUNE_LAYERS} layers\")\nprint(f\"ì¦ê°•: 4ê°œ (Contrast ì¶”ê°€)\")\nprint(\"=\"*60)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================================================================\n# Cell 3: í•™ìŠµ (ê²€ì¦ëœ ì„¤ì • + Epochsë§Œ ì¦ê°€)\n# ===================================================================\nprint(\"\\nğŸš€ í•™ìŠµ ì‹œì‘!\")\nprint(\"=\"*60)\n\nfrom sklearn.utils import class_weight\nimport pickle\n\ngc.collect()\n\nclass_weights = class_weight.compute_class_weight(\n    'balanced',\n    classes=np.unique(y_train),\n    y=y_train\n)\nclass_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\nprint(f\"âœ… Class weights: {class_weight_dict}\\n\")\n\n# Dataset ìƒì„±\nprint(\"Dataset ìƒì„±...\\n\")\n\nBATCH_SIZE = 10\n\ndef augment_data(image, label):\n    image = data_augmentation(image, training=True)\n    return image, label\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntrain_dataset = train_dataset.shuffle(buffer_size=10000, seed=42)\ntrain_dataset = train_dataset.batch(BATCH_SIZE)\ntrain_dataset = train_dataset.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\ntrain_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n\nval_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\nval_dataset = val_dataset.batch(BATCH_SIZE)\nval_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n\nprint(f\"[ì™„ë£Œ] Dataset ì¤€ë¹„!\")\nprint(f\"   Train: {len(y_train):,} samples\")\nprint(f\"   Val: {len(y_val):,} samples\\n\")\n\ndel X_train\ngc.collect()\nprint(\"[ì™„ë£Œ] ë©”ëª¨ë¦¬ ì •ë¦¬\\n\")\n\n# Callbacks\ncheckpoint = callbacks.ModelCheckpoint(\n    'best_model_improved.weights.h5',\n    monitor='val_accuracy',\n    save_best_only=True,\n    save_weights_only=True,\n    mode='max',\n    verbose=1\n)\n\nearly_stop = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=10,  # ì›ë˜ëŒ€ë¡œ\n    restore_best_weights=True,\n    verbose=1\n)\n\nreduce_lr = callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=3,  # ì›ë˜ëŒ€ë¡œ\n    min_lr=1e-7,\n    verbose=1\n)\n\nEPOCHS = 35  # 25 â†’ 35 (ì´ê²ƒë§Œ ì¦ê°€)\n\nprint(\"=\"*60)\nprint(\"ğŸ”¥ í•™ìŠµ ì„¤ì •\")\nprint(\"=\"*60)\nprint(f\"Epochs: {EPOCHS} (25â†’35 ì¦ê°€)\")\nprint(f\"Batch: {BATCH_SIZE}\")\nprint(f\"LR: 0.0005\")\nprint(f\"Focal Loss: gamma=1.5 (ê²€ì¦ë¨)\")\nprint(f\"ëª©í‘œ: 76.5-77.5%\")\nprint(\"=\"*60)\n\ntry:\n    history = model.fit(\n        train_dataset,\n        epochs=EPOCHS,\n        validation_data=val_dataset,\n        class_weight=class_weight_dict,\n        callbacks=[checkpoint, early_stop, reduce_lr],\n        verbose=1\n    )\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"âœ… í•™ìŠµ ì™„ë£Œ!\")\n    print(\"=\"*60)\n    \n    best_val_acc = max(history.history['val_accuracy'])\n    best_epoch = history.history['val_accuracy'].index(best_val_acc) + 1\n    \n    print(f\"\\nğŸ“Š ìµœì¢… ê²°ê³¼:\")\n    print(f\"   ìµœê³  ì •í™•ë„: {best_val_acc*100:.2f}%\")\n    print(f\"   ë‹¬ì„± Epoch: {best_epoch}/{EPOCHS}\")\n    \n    improvement = (best_val_acc - 0.7635) * 100\n    print(f\"\\nğŸ¯ ê°œì„ :\")\n    print(f\"   ì´ì „: 76.35%\")\n    print(f\"   í˜„ì¬: {best_val_acc*100:.2f}%\")\n    print(f\"   í–¥ìƒ: {improvement:+.2f}%p\")\n    \n    if best_val_acc >= 0.77:\n        print(f\"\\nğŸ‰ ëª©í‘œ ë‹¬ì„±!\")\n    elif best_val_acc >= 0.765:\n        print(f\"\\nâœ… ê°œì„  ì„±ê³µ!\")\n    else:\n        print(f\"\\nğŸ“Š ì•½ê°„ ê°œì„ \")\n    \n    # ì €ì¥\n    print(\"\\nğŸ’¾ ì €ì¥ ì¤‘...\")\n    with open('history_improved.pkl', 'wb') as f:\n        pickle.dump(history.history, f)\n    \n    model.save('final_mobilenet_improved.keras')\n    \n    print(\"\\nâœ… ì €ì¥ ì™„ë£Œ:\")\n    print(\"   - history_improved.pkl\")\n    print(\"   - final_mobilenet_improved.keras\")\n    print(\"   - best_model_improved.weights.h5\")\n    \n    import os\n    size = os.path.getsize('final_mobilenet_improved.keras') / (1024**2)\n    print(f\"\\nğŸ“¦ í¬ê¸°: {size:.1f} MB\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"ğŸš¨ Save Version í•˜ì„¸ìš”!\")\n    print(\"=\"*60)\n    print(\"Version name: 'mobilenet-improved-77pct'\")\n    print(\"=\"*60)\n\nexcept Exception as e:\n    print(f\"\\nâŒ ERROR: {e}\")\n    import traceback\n    traceback.print_exc()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}