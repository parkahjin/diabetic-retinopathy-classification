# 당뇨망막병증 분류 AI 프로젝트
## 완전 문서화

---

**프로젝트 정보**
- **유형:** 의료 AI - 이진 분류
- **데이터셋:** Kaggle 당뇨망막병증 탐지
- **Phase 1 모델 정확도:** 76.64%
- **최종 정확도 (TTA + 임계값 최적화):** 77.18%
- **모델:** MobileNetV2
- **작성일:** 2024년 11월 11일

---

## 목차

1. [프로젝트 개요](#1-프로젝트-개요)
2. [데이터 전처리](#2-데이터-전처리)
   - 2.1 [데이터 로드 및 분할](#21-데이터-로드-및-분할)
   - 2.2 [오버샘플링](#22-오버샘플링)
   - 2.3 [이미지 전처리](#23-이미지-전처리)
3. [모델 학습 (Phase 1)](#3-모델-학습-phase-1)
   - 3.1 [모델 구조](#31-모델-구조)
   - 3.2 [학습 설정](#32-학습-설정)
   - 3.3 [학습 결과](#33-학습-결과)
4. [성능 개선](#4-성능-개선)
   - 4.1 [TTA (Test Time Augmentation)](#41-tta-test-time-augmentation)
   - 4.2 [임계값 최적화](#42-임계값-최적화)
5. [최종 결과](#5-최종-결과)
6. [핵심 학습 내용](#6-핵심-학습-내용)
7. [결론](#7-결론)

---

## 1. 프로젝트 개요

### 목표
망막 이미지에서 **당뇨망막병증을 탐지**하는 이진 분류 AI 모델 개발:
- **정상** (Grade 0)
- **비정상** (Grade 1-4)

### 도전 과제
**메모리 제약** (Kaggle 30GB RAM) 환경에서 불균형한 의료 이미지 데이터로 높은 정확도 달성

### 데이터셋
- **출처:** Kaggle Diabetic Retinopathy Detection
- **총 이미지:** 35,126개의 망막 이미지
- **원본 클래스:** 5단계 중증도 (0-4)
- **변환:** 이진 분류 (정상 vs 비정상)

### 목표 설정
- **목표 정확도:** 80% (포트폴리오 목표)
- **달성 정확도:** 76.64%

---

## 2. 데이터 전처리

### 2.1 데이터 로드 및 분할

#### 이진 분류 변환
```python
# Grade 0 → 정상 (0)
# Grade 1-4 → 비정상 (1)
labels_df['binary_label'] = labels_df['level'].apply(lambda x: 0 if x == 0 else 1)
```

#### 원본 클래스 분포
| 클래스 | 개수 | 비율 |
|-------|------|------|
| 정상 (0) | 25,810 | 73.5% |
| 비정상 (1-4) | 9,316 | 26.5% |
| **불균형 비율** | **2.77:1** | |

#### Train/Val 분할
```python
train_df, val_df = train_test_split(
    labels_df,
    test_size=0.2,
    stratify=labels_df['binary_label'],
    random_state=42
)
```

**분할 결과:**
- **Train:** 28,100개 이미지 (80%)
- **Val:** 7,026개 이미지 (20%)
- **방법:** Stratified split (클래스 비율 유지)

---

### 2.2 오버샘플링

#### 전략
비정상 클래스에 대한 **랜덤 오버샘플링** (중복 허용)
```python
# 클래스별 분리
normal_df = train_df[train_df['binary_label'] == 0]
abnormal_df = train_df[train_df['binary_label'] == 1]

# 비정상 클래스를 정상 클래스 개수만큼 오버샘플링
target_count = len(normal_df)
abnormal_oversampled = abnormal_df.sample(
    n=target_count, 
    replace=True,  # 중복 허용
    random_state=42
)

# 결합 및 섞기
train_balanced = pd.concat([normal_df, abnormal_oversampled])
train_balanced = train_balanced.sample(frac=1, random_state=42)
```

#### 균형 잡힌 Train 세트
| 클래스 | 개수 | 비율 |
|-------|------|------|
| 정상 | 20,647 | 50.0% |
| 비정상 | 20,647 | 50.0% |
| **총합** | **41,294** | |
| **비율** | **1:1** | ✅ 완벽한 균형 |

#### 검증 세트
**원본 분포 유지** (오버샘플링 안 함)
| 클래스 | 개수 | 비율 |
|-------|------|------|
| 정상 | 5,163 | 73.5% |
| 비정상 | 1,863 | 26.5% |

---

### 2.3 이미지 전처리

#### 전처리 파이프라인
```python
IMG_SIZE = 96

def preprocess_image(image_path):
    # 1. 이미지 로드
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # 2. CLAHE (대비 제한 적응 히스토그램 평활화)
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l_clahe = clahe.apply(l)
    
    lab_clahe = cv2.merge([l_clahe, a, b])
    img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2RGB)
    
    # 3. 96×96 리사이즈
    img_resized = cv2.resize(img_clahe, (IMG_SIZE, IMG_SIZE))
    
    # 4. 정규화 [0-255] → [0-1]
    img_normalized = img_resized.astype(np.float32) / 255.0
    
    return img_normalized
```

#### 전처리 선택 이유

**1. CLAHE (대비 제한 적응 히스토그램 평활화)**
- 망막 이미지의 대비 향상
- 혈관 및 병변 가시성 개선
- Clip limit: 2.0, Tile grid: 8×8

**2. 96×96 해상도**
- 메모리 최적화 (30GB RAM 제약)
- MobileNetV2는 낮은 해상도에서도 잘 작동
- 대안: 224×224는 13GB+ RAM 필요

**3. 정규화**
- [0-255] → [0-1]로 변환하여 학습 안정화
- Float32 정밀도 사용

#### 메모리 사용량
- **Train:** ~4.5 GB
- **Val:** ~1.0 GB
- **총합:** ~5.5 GB
- **저장 형식:** NumPy 배열 (.npy)

---

## 3. 모델 학습 (Phase 1)

### 3.1 모델 구조
```python
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models

# 베이스 모델
base_model = MobileNetV2(
    input_shape=(96, 96, 3),
    include_top=False,
    weights='imagenet'
)

# Fine-tuning: 마지막 50개 레이어만 학습
FINE_TUNE_LAYERS = 50
for layer in base_model.layers[:-FINE_TUNE_LAYERS]:
    layer.trainable = False

# 커스텀 헤드
model = models.Sequential([
    layers.Input(shape=(96, 96, 3)),
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(1, activation='sigmoid', dtype='float32')
])
```

#### MobileNetV2를 선택한 이유

✅ **장점:**
- **저해상도 이미지**(96×96)에 최적화
- **경량** 아키텍처 (155개 레이어)
- 효율적인 **학습 및 추론**
- 모바일/임베디드 환경에 적합

❌ **거부된 대안들:**
- ResNet50: 224×224+ 해상도 필요
- DenseNet121: 96×96에는 너무 깊음
- EfficientNet: 유사한 메모리 문제

---

### 3.2 학습 설정
```python
# 클래스 불균형 처리를 위한 Focal Loss
def focal_loss(gamma=1.5, alpha=0.5):
    def focal_loss_fixed(y_true, y_pred):
        epsilon = tf.keras.backend.epsilon()
        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)
        
        y_true = tf.cast(y_true, tf.float32)
        p_t = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)
        alpha_t = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)
        focal_weight = tf.pow(1.0 - p_t, gamma)
        focal_loss = -alpha_t * focal_weight * tf.math.log(p_t)
        
        return tf.reduce_mean(focal_loss)
    
    return focal_loss_fixed

# 컴파일
model.compile(
    optimizer=Adam(learning_rate=0.0005),
    loss=focal_loss(gamma=1.5, alpha=0.5),
    metrics=['accuracy']
)
```

#### 하이퍼파라미터

| 파라미터 | 값 | 선택 이유 |
|---------|---|----------|
| **손실 함수** | Focal Loss (γ=1.5, α=0.5) | 클래스 불균형 처리 |
| **옵티마이저** | Adam | 적응형 학습률 |
| **학습률** | 0.0005 | 안정적인 수렴 |
| **배치 크기** | 10 | 메모리 최적화 |
| **에폭** | 35 | 충분한 학습 시간 |
| **EarlyStopping** | Patience=10 | 과적합 방지 |
| **ReduceLR** | Factor=0.5, Patience=3 | 학습 미세 조정 |

#### 데이터 증강
```python
data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),      # 좌우 반전
    layers.RandomRotation(0.1),          # 회전 (±10%)
    layers.RandomZoom(0.1),              # 확대/축소 (±10%)
    layers.RandomContrast(0.1),          # 대비 조정 (±10%)
])
```

---

### 3.3 학습 결과

#### 학습 과정
```
Epoch 1/35
- 학습: accuracy: 0.5142 | loss: 0.1657
- 검증: val_accuracy: 0.6855 | val_loss: 0.1128
→ 모델 저장 (첫 개선)

Epoch 2/35
- 학습: accuracy: 0.5608 | loss: 0.1208
- 검증: val_accuracy: 0.7249 | val_loss: 0.1053
→ 모델 저장 (개선: 0.6855 → 0.7249)

Epoch 3/35
- 학습: accuracy: 0.5868 | loss: 0.1195
- 검증: val_accuracy: 0.7344 | val_loss: 0.1038
→ 모델 저장 (개선: 0.7249 → 0.7344)

Epoch 4/35
- 학습: accuracy: 0.5968 | loss: 0.1183
- 검증: val_accuracy: 0.7398 | val_loss: 0.1020
→ 모델 저장 (개선: 0.7344 → 0.7398)

Epoch 5/35
- 학습: accuracy: 0.6125 | loss: 0.1168
- 검증: val_accuracy: 0.7432 | val_loss: 0.0984
→ 모델 저장 (개선: 0.7398 → 0.7432)

Epoch 6/35
- 학습: accuracy: 0.6193 | loss: 0.1156
- 검증: val_accuracy: 0.7515 | val_loss: 0.0963
→ 모델 저장 (개선: 0.7432 → 0.7515)

...

Epoch 13/35
- 학습: accuracy: 0.6679 | loss: 0.1081
- 검증: val_accuracy: 0.7664 | val_loss: 0.0946
→ 모델 저장 (개선: 0.7604 → 0.7664) ✨ 최고 성능!

Epoch 14/35
- 학습: accuracy: 0.6755 | loss: 0.1067
- 검증: val_accuracy: 0.7663 | val_loss: 0.0976
→ 개선 없음 (0.7664 유지)

Epoch 15/35
- 검증: val_accuracy: 0.7514 | val_loss: 0.0980
→ 개선 없음 (3 에폭 연속)

Epoch 16/35
- Learning rate 감소: 0.0005 → 0.00025
- 검증: val_accuracy: 0.7498 | val_loss: 0.0963
→ 개선 없음 (6 에폭 연속)

Epoch 17/35
- 검증: val_accuracy: 0.7568 | val_loss: 0.0959
→ 개선 없음 (7 에폭 연속)

Epoch 18/35
- 검증: val_accuracy: 0.7098 | val_loss: 0.1010
→ 개선 없음 (8 에폭 연속)

...

Epoch 23/35
- Early stopping 작동 (10 에폭 동안 개선 없음)
- 학습 종료
```

#### Phase 1 최종 결과

**최고 모델 저장 시점:** Epoch 13/35
```
=================================================================
🎯 최고 성능 달성!
=================================================================
검증 정확도: 76.64% (0.7664)
검증 손실: 0.0946
학습 정확도: 66.79% (0.6679)
학습 손실: 0.1081
=================================================================
```

**학습 요약:**
- **최고 검증 정확도:** **76.64%** (Epoch 13)
- **학습 시간:** 약 2시간
- **총 에폭:** 23 (early stopped at Epoch 23)
- **Early Stopping:** Patience 10 에폭 작동
- **Learning Rate 감소:** Epoch 16에서 0.0005 → 0.00025

#### 주요 관찰 사항

✅ **성공 요인:**
- **점진적 향상:** 68.55% (Epoch 1) → 76.64% (Epoch 13)
- **안정적 학습 곡선:** 지속적인 개선 (Epoch 1-13)
- **과적합 방지:** Early stopping으로 최적 모델 보존
- **Learning rate 조정:** ReduceLROnPlateau 효과적 작동

⚠️ **도전 과제:**
- **Epoch 13 이후 정체:** 10 에폭 동안 개선 없음
- **Train-Val 간격:** 학습 66.79% vs 검증 76.64% (일반화 여지)
- **목표 대비 부족:** 80% 목표에 3.36%p 부족

#### 학습 패턴 분석

**Phase 1 (Epoch 1-6): 급격한 상승**
- 68.55% → 75.15% (6.6%p 향상)
- 모델이 기본 패턴 학습

**Phase 2 (Epoch 7-13): 미세 조정**
- 75.15% → 76.64% (1.49%p 향상)
- 세부 특징 학습 및 최적화

**Phase 3 (Epoch 14-23): 정체 및 종료**
- 76.64% 이상 개선 없음
- Learning rate 감소해도 효과 미미
- Early stopping 작동

---

## 4. 성능 개선

### 4.1 TTA (Test Time Augmentation)

#### 전략
추론 시 **5가지 다른 증강**을 적용하고 예측을 평균:
```python
# 1. 원본
pred_original = model.predict(X_val, batch_size=32)

# 2. 좌우 반전
pred_flip_lr = model.predict(np.flip(X_val, axis=2), batch_size=32)

# 3. 상하 반전
pred_flip_ud = model.predict(np.flip(X_val, axis=1), batch_size=32)

# 4. 좌우+상하 반전
pred_flip_both = model.predict(
    np.flip(np.flip(X_val, axis=1), axis=2), 
    batch_size=32
)

# 5. 밝기 조정
pred_bright = model.predict(np.clip(X_val * 1.1, 0, 255), batch_size=32)

# 앙상블 평균
predictions_tta = (pred_original + pred_flip_lr + pred_flip_ud + 
                   pred_flip_both + pred_bright) / 5.0
```

#### 결과

| 방법 | 정확도 | 개선 |
|-----|-------|------|
| Phase 1 (기본) | 76.64% | - |
| + TTA | **77.07%** | **+0.43%p** |

#### TTA가 효과적인 이유
- 다양한 증강이 서로 다른 관점을 포착
- 모델의 불확실성 감소
- 이미지 변형에 대한 강건성 향상

---

### 4.2 임계값 최적화

#### 전략
최적의 분류 임계값 탐색 (기본값: 0.5)
```python
best_threshold = 0.5
best_accuracy = 0

# 0.30 ~ 0.70 범위에서 테스트
for threshold in np.arange(0.30, 0.71, 0.01):
    y_pred = (predictions_tta > threshold).astype(int).flatten()
    accuracy = accuracy_score(y_val, y_pred)
    
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_threshold = threshold
```

#### 결과

| 방법 | 임계값 | 정확도 | 개선 |
|-----|-------|-------|------|
| TTA | 0.500 | 77.07% | - |
| + 임계값 최적화 | **0.490** | **77.18%** | **+0.11%p** |

#### 최적 임계값: 0.490
- **왜 0.5가 아닌가?** 검증 세트가 불균형(73.5% vs 26.5%)
- 임계값을 약간 낮추면 **True Positives** 증가 (비정상 케이스 탐지)
- 트레이드오프: False Positives 약간 증가하지만 전체 정확도 향상

---

## 5. 최종 결과

### 성능 요약

| 단계 | 정확도 | 개선 |
|-----|-------|------|
| **Phase 1 (기본 모델)** | 76.64% | - |
| **+ TTA** | 77.07% | +0.43%p |
| **+ 임계값 최적화** | **77.18%** | **+0.11%p** |
| **총 개선** | | **+0.54%p** |

### 혼동 행렬 (Confusion Matrix)
```
                예측
                정상    비정상
실제 정상       4,958    205
     비정상     1,398    465
```

| 지표 | 값 |
|-----|---|
| **True Negatives (TN)** | 4,958 |
| **False Positives (FP)** | 205 |
| **False Negatives (FN)** | 1,398 |
| **True Positives (TP)** | 465 |

### 클래스별 성능

| 클래스 | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| **정상** | 0.7801 | 0.9603 | 0.8608 | 5,163 |
| **비정상** | 0.6940 | 0.2496 | 0.3672 | 1,863 |
| **정확도** | | | **0.7718** | 7,026 |
| **Macro Avg** | 0.7370 | 0.6049 | 0.6140 | 7,026 |
| **Weighted Avg** | 0.7572 | 0.7718 | 0.7299 | 7,026 |

### 핵심 인사이트

✅ **강점:**
- **정상 클래스의 높은 Recall (96.0%)**: 건강한 환자 식별에 탁월
- **정상 클래스의 좋은 Precision (78.0%)**: False alarm 낮음
- **전체 정확도 77.18%**: 목표(80%) 근접

⚠️ **약점:**
- **비정상 클래스의 낮은 Recall (25.0%)**: 병변 케이스 놓침
- **클래스 불균형의 영향**: 검증 세트에서 정상 73.5% vs 비정상 26.5%

#### 의료 AI 관점
- **False Negative가 치명적**: 병을 정상으로 오판하면 위험
- **현재 FN = 1,398**: 비정상 환자 중 75%를 놓침
- **개선 방향**: Recall 향상 필요 (추가 데이터, 모델 앙상블 등)

---

## 6. 핵심 학습 내용

### 기술적 성과

✅ **달성한 것:**
1. **MobileNetV2 최적화** (96×96 저해상도)
2. **Focal Loss**로 클래스 불균형 처리
3. **TTA** 구현으로 +0.43%p 향상
4. **임계값 최적화**로 +0.11%p 추가 향상
5. **메모리 제약** 극복 (Kaggle 30GB)

### 중요한 발견

#### 1. 해상도와 모델 선택의 관계
- **MobileNetV2**: 96×96에서 잘 작동 ✅
- **ResNet50/DenseNet**: 96×96에서 26%/73% 패턴 발생 ❌
- **교훈**: 모델 선택은 해상도 제약을 고려해야 함

#### 2. 저장/로드 문제
- **문제**: `.keras` 파일 저장 후 로드 시 성능 저하
- **원인**: 정규화 불일치 (학습 시 0-255, 추론 시 0-1)
- **해결**: 전처리 파이프라인 일관성 유지 필수

#### 3. 클래스 불균형 처리
- **오버샘플링**: Train 세트만 적용 (1:1 균형)
- **검증 세트**: 원본 분포 유지 (실제 상황 반영)
- **Focal Loss**: 추가 보정 효과

#### 4. 메모리 최적화 전략
- **배치 크기**: 10으로 제한
- **해상도**: 96×96 (224×224 대비 1/5 메모리)
- **NumPy 저장**: .npy 형식으로 빠른 로드

#### 5. 학습 조기 종료의 중요성
- **Early Stopping**: Patience=10으로 과적합 방지
- **최적 모델 저장**: Epoch 13 시점의 모델이 최고 성능
- **Learning Rate 감소**: 정체 시 자동 조정

### 실패와 교훈

❌ **실패한 시도들:**
1. ResNet50, DenseNet121 → 96×96에서 작동 안 함
2. Phase 2 모델 시도 → 설정 변경 시 성능 급락
3. 초기 앙상블 시도 → 입력 해상도 불일치
4. Epoch 13 이후 추가 학습 → 개선 없음 (정체)

💡 **배운 점:**
- **검증된 설정 유지**: Phase 1 설정이 최적
- **체계적 디버깅**: 문제 발생 시 단계별 확인
- **재현성**: 코드와 설정의 일관성 유지
- **적시 종료**: 과적합보다 조기 종료가 낫다

---

## 7. 결론

### 프로젝트 성과

**목표 대비 달성도:**
- **목표 정확도:** 80%
- **달성 정확도:** 77.18%
- **달성률:** 96.5%

**기술적 완성도:**
- ✅ 완전한 파이프라인 구축 (전처리 → 학습 → 평가)
- ✅ 메모리 제약 환경에서 최적화
- ✅ 성능 개선 기법 적용 (TTA, Threshold)
- ✅ 재현 가능한 코드 작성

### 포트폴리오 가치

**이 프로젝트가 보여주는 것:**
1. **의료 AI 이해도**: 망막 이미지 처리, 클래스 불균형 처리
2. **문제 해결 능력**: 메모리 제약, 모델 선택, 디버깅
3. **최적화 경험**: 제한된 리소스에서 최대 성능 추출
4. **완성도**: 전처리부터 평가까지 전 과정 구현

### 향후 개선 방향

**단기 개선 (즉시 가능):**
- Grad-CAM 시각화 추가 (모델 해석성)
- Gradio 데모 구축 (상호작용 가능)
- 추가 TTA 기법 (회전, 스케일)

**중장기 개선 (리소스 필요):**
- 더 큰 해상도 (224×224) 시도
- 앙상블 모델 (MobileNetV2 + EfficientNet)
- 외부 데이터셋으로 Fine-tuning
- Recall 향상 전략 (비정상 탐지율 개선)

### 마무리

이 프로젝트는 **제약된 환경에서도 체계적인 접근**으로 의미 있는 결과를 도출할 수 있음을 보여줍니다. 
77.18%의 정확도는 목표에는 약간 못 미쳤지만, 의료 AI 분야에서 충분히 의미 있는 수준이며, 
**프로세스, 문제 해결, 최적화 경험**이 더 큰 가치를 가집니다.

특히 **Epoch 13에서 최고 성능(76.64%)을 달성**하고, TTA와 임계값 최적화를 통해 **77.18%까지 향상**시킨 것은 
단순히 모델을 학습시키는 것을 넘어, **성능 개선을 위한 다양한 기법**을 실제로 적용하고 검증했다는 점에서 
포트폴리오로서 큰 가치를 지닙니다.

---

**프로젝트 완료일:** 2024년 11월 11일  
**총 소요 시간:** 약 15시간 (전처리 3시간 + 학습 2시간 + 개선 1시간 + 디버깅 9시간)  
**최종 성과:** 77.18% 정확도 달성 (Phase 1: 76.64% → TTA + Threshold: 77.18%) ✅

---

## 부록

### A. 주요 코드 스니펫

#### 전처리 함수
```python
def preprocess_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # CLAHE
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l_clahe = clahe.apply(l)
    lab_clahe = cv2.merge([l_clahe, a, b])
    img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2RGB)
    
    # 리사이즈 및 정규화
    img_resized = cv2.resize(img_clahe, (96, 96))
    img_normalized = img_resized.astype(np.float32) / 255.0
    
    return img_normalized
```

#### Focal Loss
```python
def focal_loss(gamma=1.5, alpha=0.5):
    def focal_loss_fixed(y_true, y_pred):
        epsilon = tf.keras.backend.epsilon()
        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)
        
        y_true = tf.cast(y_true, tf.float32)
        p_t = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)
        alpha_t = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)
        focal_weight = tf.pow(1.0 - p_t, gamma)
        focal_loss = -alpha_t * focal_weight * tf.math.log(p_t)
        
        return tf.reduce_mean(focal_loss)
    
    return focal_loss_fixed
```

#### TTA
```python
# 5가지 증강 평균
predictions_tta = (
    model.predict(X_val) +                                      # 원본
    model.predict(np.flip(X_val, axis=2)) +                    # 좌우
    model.predict(np.flip(X_val, axis=1)) +                    # 상하
    model.predict(np.flip(np.flip(X_val, axis=1), axis=2)) +   # 양방향
    model.predict(np.clip(X_val * 1.1, 0, 255))                # 밝기
) / 5.0
```

### B. 참고 자료

**데이터셋:**
- [Kaggle Diabetic Retinopathy Detection](https://www.kaggle.com/c/diabetic-retinopathy-detection)

**논문:**
- Focal Loss for Dense Object Detection (Lin et al., 2017)
- MobileNetV2: Inverted Residuals and Linear Bottlenecks (Sandler et al., 2018)

**기술 스택:**
- TensorFlow/Keras
- OpenCV
- NumPy, Pandas
- Scikit-learn
- Matplotlib

### C. 프로젝트 타임라인

```
[시작] 데이터 준비 (3시간)
  ↓
[Week 1] Phase 1 모델 학습 (2시간)
  ├─ Epoch 1-6: 급격한 상승 (68% → 75%)
  ├─ Epoch 7-13: 미세 조정 (75% → 76.64%)
  └─ Epoch 14-23: 정체 및 종료
  ↓
[Week 2] 성능 개선 (1시간)
  ├─ TTA 구현: +0.43%p
  └─ 임계값 최적화: +0.11%p
  ↓
[Week 3] 디버깅 및 최적화 (9시간)
  ├─ 저장/로드 문제 해결
  ├─ 메모리 최적화
  └─ 재현성 확보
  ↓
[완료] 최종 정확도: 77.18% ✅
```

---

**문서 끝**
